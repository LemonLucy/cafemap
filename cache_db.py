import os
import json
import psycopg2
from psycopg2.extras import RealDictCursor

DATABASE_URL = os.getenv('DATABASE_URL')

def get_db_connection():
    """PostgreSQL Ïó∞Í≤∞"""
    if not DATABASE_URL:
        return None
    return psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)

def init_cache_db():
    """Ï∫êÏãú ÌÖåÏù¥Î∏î ÏÉùÏÑ±"""
    conn = get_db_connection()
    if not conn:
        return
    
    try:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS cafe_cache (
                    id SERIAL PRIMARY KEY,
                    cafe_name VARCHAR(255) NOT NULL,
                    cafe_address VARCHAR(500) NOT NULL,
                    region VARCHAR(100),
                    cache_version VARCHAR(20),
                    result JSONB NOT NULL,
                    hit_count INTEGER DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(cafe_name, cafe_address, cache_version)
                )
            """)
            
            # Ïù∏Îç±Ïä§ ÏÉùÏÑ±
            cur.execute("""
                CREATE INDEX IF NOT EXISTS idx_cafe_lookup 
                ON cafe_cache(cafe_name, cafe_address, cache_version)
            """)
            cur.execute("""
                CREATE INDEX IF NOT EXISTS idx_region 
                ON cafe_cache(region)
            """)
            
            conn.commit()
            print("‚úÖ Cache DB initialized")
    except Exception as e:
        print(f"‚ùå Cache DB init error: {e}")
    finally:
        conn.close()

def should_cache_to_postgres(cafe_address, total_score, hit_count=1):
    """Postgres Ï†ÄÏû• Ïó¨Î∂Ä Í≤∞Ï†ï"""
    # ÏÑúÏö∏ÏùÄ Î¨¥Ï°∞Í±¥ Ï†ÄÏû•
    if 'ÏÑúÏö∏' in cafe_address:
        return True
    
    # Í≤ΩÍ∏∞/Ïù∏Ï≤ú Ï£ºÏöî ÎèÑÏãú
    major_cities = ['ÏàòÏõê', 'ÏÑ±ÎÇ®', 'Í≥†Ïñë', 'Ïö©Ïù∏', 'Î∂ÄÏ≤ú', 'ÏïàÏÇ∞', 'ÏïàÏñë', 'ÎÇ®ÏñëÏ£º', 'ÌôîÏÑ±', 'ÌèâÌÉù', 'Ïù∏Ï≤ú']
    if any(city in cafe_address for city in major_cities):
        return True
    
    # ÏßÄÎ∞© ÎèÑÏãúÎäî Ï°∞Ìöå 2Ìöå Ïù¥ÏÉÅ ÎòêÎäî Í≥†ÎìùÏ†ê
    if hit_count >= 2 or total_score >= 3.0:
        return True
    
    return False

def get_region_from_address(address):
    """Ï£ºÏÜåÏóêÏÑú ÏßÄÏó≠ Ï∂îÏ∂ú"""
    parts = address.split()
    if len(parts) > 0:
        # "ÏÑúÏö∏ÌäπÎ≥ÑÏãú" ‚Üí "ÏÑúÏö∏", "Í≤ΩÍ∏∞ÎèÑ ÏàòÏõêÏãú" ‚Üí "ÏàòÏõê"
        region = parts[0].replace('ÌäπÎ≥ÑÏãú', '').replace('Í¥ëÏó≠Ïãú', '').replace('ÎèÑ', '')
        if len(parts) > 1 and 'Ïãú' in parts[1]:
            region = parts[1].replace('Ïãú', '')
        return region
    return 'unknown'

def get_cached_result(cafe_name, cafe_address, cache_version):
    """Ï∫êÏãúÏóêÏÑú Í≤∞Í≥º Ï°∞Ìöå (Postgres ‚Üí Î©îÎ™®Î¶¨ Ïàú)"""
    # 1Ï∞®: Î©îÎ™®Î¶¨ Ï∫êÏãú
    from app_server import blog_cache
    cache_key = f"{cache_version}_{cafe_name}_{cafe_address}"
    if cache_key in blog_cache:
        return blog_cache[cache_key]
    
    # 2Ï∞®: Postgres
    conn = get_db_connection()
    if not conn:
        return None
    
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT result, hit_count FROM cafe_cache 
                WHERE cafe_name = %s AND cafe_address = %s AND cache_version = %s
            """, (cafe_name, cafe_address, cache_version))
            
            row = cur.fetchone()
            if row:
                # Ï°∞ÌöåÏàò Ï¶ùÍ∞Ä
                cur.execute("""
                    UPDATE cafe_cache 
                    SET hit_count = hit_count + 1, updated_at = CURRENT_TIMESTAMP
                    WHERE cafe_name = %s AND cafe_address = %s AND cache_version = %s
                """, (cafe_name, cafe_address, cache_version))
                conn.commit()
                
                # Î©îÎ™®Î¶¨ Ï∫êÏãúÏóêÎèÑ Ï†ÄÏû•
                result = row['result']
                blog_cache[cache_key] = result
                return result
    except Exception as e:
        print(f"‚ùå Cache read error: {e}")
    finally:
        conn.close()
    
    return None

def save_cached_result(cafe_name, cafe_address, cache_version, result):
    """Í≤∞Í≥ºÎ•º Ï∫êÏãúÏóê Ï†ÄÏû•"""
    from app_server import blog_cache, MAX_CACHE_SIZE
    
    # Î©îÎ™®Î¶¨ Ï∫êÏãúÏóê Ìï≠ÏÉÅ Ï†ÄÏû•
    cache_key = f"{cache_version}_{cafe_name}_{cafe_address}"
    if len(blog_cache) >= MAX_CACHE_SIZE:
        oldest_key = next(iter(blog_cache))
        del blog_cache[oldest_key]
    blog_cache[cache_key] = result
    
    # Postgres Ï†ÄÏû• Ïó¨Î∂Ä Í≤∞Ï†ï
    region = get_region_from_address(cafe_address)
    total_score = result.get('totalScore', 0)
    
    if not should_cache_to_postgres(cafe_address, total_score):
        return  # Î©îÎ™®Î¶¨Îßå Ï†ÄÏû•
    
    # PostgresÏóê Ï†ÄÏû•
    conn = get_db_connection()
    if not conn:
        return
    
    try:
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO cafe_cache (cafe_name, cafe_address, region, cache_version, result)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (cafe_name, cafe_address, cache_version) 
                DO UPDATE SET 
                    result = EXCLUDED.result,
                    hit_count = cafe_cache.hit_count + 1,
                    updated_at = CURRENT_TIMESTAMP
            """, (cafe_name, cafe_address, region, cache_version, json.dumps(result)))
            conn.commit()
            print(f"üíæ Cached to Postgres: {cafe_name} ({region})")
    except Exception as e:
        print(f"‚ùå Cache save error: {e}")
    finally:
        conn.close()

def get_cache_stats():
    """Ï∫êÏãú ÌÜµÍ≥Ñ"""
    conn = get_db_connection()
    if not conn:
        return {"error": "DB not connected"}
    
    try:
        with conn.cursor() as cur:
            cur.execute("""
                SELECT 
                    COUNT(*) as total_cafes,
                    SUM(hit_count) as total_hits,
                    COUNT(DISTINCT region) as regions,
                    pg_size_pretty(pg_total_relation_size('cafe_cache')) as db_size
                FROM cafe_cache
            """)
            stats = cur.fetchone()
            
            cur.execute("""
                SELECT region, COUNT(*) as count 
                FROM cafe_cache 
                GROUP BY region 
                ORDER BY count DESC 
                LIMIT 10
            """)
            top_regions = cur.fetchall()
            
            return {
                "stats": dict(stats),
                "top_regions": [dict(r) for r in top_regions]
            }
    except Exception as e:
        return {"error": str(e)}
    finally:
        conn.close()
